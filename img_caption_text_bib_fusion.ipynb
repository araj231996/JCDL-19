{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Concatenate, Dropout, Add, Lambda\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from keras.engine.topology import Layer\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"ARTINT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 13 13:56:39 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0  On |                  N/A |\n",
      "| 40%   64C    P2    75W / 250W |   9083MiB / 11172MiB |     24%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 29%   51C    P2    57W / 250W |  10681MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 30%   52C    P0    69W / 250W |      2MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 29%   51C    P2    83W / 250W |   6105MiB / 11172MiB |     83%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "|  0%   46C    P8    18W / 250W |      2MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 23%   37C    P8    17W / 250W |    706MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 26%   47C    P2    57W / 250W |   2302MiB / 11172MiB |     23%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "|  0%   35C    P8    18W / 250W |      2MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4670      G   /usr/lib/xorg/Xorg                            50MiB |\n",
      "|    0      9764      C   python                                      8809MiB |\n",
      "|    0     24425      C   ...1/tanik/anaconda3/envs/tfgpu/bin/python   209MiB |\n",
      "|    1     10028      C   ...r/miniconda2/envs/raghav_btp/bin/python 10175MiB |\n",
      "|    1     46423      C   ...1/tanik/anaconda3/envs/tfgpu/bin/python   495MiB |\n",
      "|    3     22182      C   python                                      2291MiB |\n",
      "|    3     22346      C   python                                      1267MiB |\n",
      "|    3     22551      C   python                                      1267MiB |\n",
      "|    3     22758      C   python                                      1267MiB |\n",
      "|    5     13418      C   /home1/tirthankar/miniconda2/bin/python      695MiB |\n",
      "|    6     35449      C   python                                      2291MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data\n",
    "train_img_filename =  pickle.load(open(DATA+\"_train_img_filename_for_img_modal_vector.p\", \"rb\"))\n",
    "train_img_feature_vector = np.load(DATA+'_train_img_modal_vector.npy')\n",
    "train_caption_feature_vector = pickle.load(open(DATA+\"_train_image_caption_feature_vector.p\", \"rb\"))\n",
    "train_text_filename = pickle.load(open(DATA+\"/JNCA_train_fulltext_filename_final.p\", \"rb\"))\n",
    "train_text_feature_vector =  np.load(DATA+\"_train_full_text_modality_feature.npy\")\n",
    "train_bib_feature_vector =  pickle.load(open(DATA+\"_train_only_bib_feature_vector_final.p\", \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "test_img_filename = pickle.load(open(DATA+\"_test_img_filename_for_img_modal_vector.p\", \"rb\"))\n",
    "test_img_feature_vector = np.load(DATA+'_test_img_modal_vector.npy')\n",
    "test_caption_feature_vector = pickle.load(open(DATA+\"_test_image_caption_feature_vector.p\", \"rb\"))\n",
    "test_text_filename = pickle.load(open(DATA+\"_test_fulltext_filename_final.p\", \"rb\"))\n",
    "test_text_feature_vector = np.load(DATA+\"_test_full_text_modality_feature.npy\")\n",
    "test_bib_feature_vector = pickle.load(open(DATA+\"_test_only_bib_feature_vector_final.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(train_img_filename))\n",
    "#print(len(train_text_filename))\n",
    "#print(train_caption_feature_vector.keys())\n",
    "#print(train_bib_feature_vector.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_img = []\n",
    "fv_img_caption = []\n",
    "fv_full_text = []\n",
    "fv_bib = []\n",
    "train_labels = []\n",
    "for i in range(len(train_img_filename)):\n",
    "    for j in range(len(train_text_filename)):\n",
    "        if train_img_filename[i] in train_text_filename[j]:\n",
    "            if train_text_filename[j] not in train_caption_feature_vector.keys():\n",
    "                continue\n",
    "            if train_text_filename[j] not in train_bib_feature_vector.keys():\n",
    "                    continue\n",
    "            fv_img.append(train_img_feature_vector[i])\n",
    "            fv_img_caption.append(train_caption_feature_vector[train_text_filename[j]])\n",
    "            fv_full_text.append(train_text_feature_vector[j])\n",
    "            fv_bib.append(train_bib_feature_vector[train_text_filename[j]])\n",
    "            label = 1.0\n",
    "            if 'neg_' in train_img_filename[i]:\n",
    "                label = 0.0\n",
    "            train_labels.append(label)\n",
    "\n",
    "fv_img = np.array(fv_img)\n",
    "fv_img_caption = np.array(fv_img_caption)\n",
    "fv_full_text = np.array(fv_full_text)\n",
    "fv_bib = np.array(fv_bib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_img_test = []\n",
    "fv_img_test_caption = []\n",
    "fv_full_text_test = []\n",
    "fv_bib_test = []\n",
    "test_labels = []\n",
    "for i in range(len(test_img_filename)):\n",
    "    for j in range(len(test_text_filename)):\n",
    "        if test_img_filename[i] in test_text_filename[j]:\n",
    "            if test_text_filename[j] not in test_caption_feature_vector.keys():\n",
    "                continue\n",
    "            if test_text_filename[j] not in test_bib_feature_vector.keys():\n",
    "                print(test_text_filename[j])\n",
    "            fv_img_test.append(test_img_feature_vector[i])\n",
    "            fv_img_test_caption.append(test_caption_feature_vector[test_text_filename[j]])\n",
    "            fv_full_text_test.append(test_text_feature_vector[j])\n",
    "            fv_bib_test.append(test_bib_feature_vector[test_text_filename[j]])\n",
    "            label = 1.0\n",
    "            if 'neg_' in test_img_filename[i]:\n",
    "                label = 0.0\n",
    "            test_labels.append(label)\n",
    "            \n",
    "fv_img_test = np.array(fv_img_test)\n",
    "fv_img_test_caption = np.array(fv_img_test_caption)\n",
    "fv_full_text_test = np.array(fv_full_text_test)\n",
    "fv_bib_test = np.array(fv_bib_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3056, 4096)\n",
      "(3056, 5716)\n",
      "(3056, 9000)\n",
      "(3056, 100)\n",
      "(768, 4096)\n",
      "(768, 5716)\n",
      "(768, 9000)\n",
      "(768, 100)\n"
     ]
    }
   ],
   "source": [
    "print(fv_img.shape)\n",
    "print(fv_img_caption.shape)\n",
    "print(fv_bib.shape)\n",
    "print(fv_full_text.shape)\n",
    "print(fv_img_test.shape)\n",
    "print(fv_img_test_caption.shape)\n",
    "print(fv_bib_test.shape)\n",
    "print(fv_full_text_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "IMG_FEATURES = Input(shape = (4096,))\n",
    "IMG_CAPTIONS = Input(shape = (5716,))\n",
    "FULL_TEXT = Input(shape = (100,))\n",
    "BIB = Input(shape = (9000,))\n",
    "\n",
    "B = Concatenate(axis = 1)([IMG_FEATURES, IMG_CAPTIONS, FULL_TEXT, BIB])\n",
    "\n",
    "P = Dense(512, activation = 'relu')(B)\n",
    "\n",
    "alpha = Dense(4, activation = 'softmax')(P)\n",
    "\n",
    "F = Lambda(lambda x : alpha[:,0:1]*IMG_FEATURES)(alpha)\n",
    "G = Lambda(lambda x : alpha[:,1:2]*IMG_CAPTIONS)(alpha)\n",
    "H = Lambda(lambda x : alpha[:,2:3]*FULL_TEXT)(alpha)\n",
    "I = Lambda(lambda x : alpha[:,3:4]*BIB)(alpha)\n",
    "Y = Concatenate(axis = -1)([F,G,H,I])\n",
    "\n",
    "Y = Dense(2000, activation = 'relu')(Y)\n",
    "Y = Dropout(rate = 0.2)(Y)\n",
    "\n",
    "Y = Dense(512, activation = 'relu')(Y)\t\t#, kernel_regularizer = regularizers.l2(0.01)\n",
    "Y = Dropout(rate = 0.25)(Y)\n",
    "\n",
    "Y = Dense(512, activation = 'relu')(Y)\n",
    "Y = Dropout(rate = 0.2)(Y)\n",
    "\n",
    "Y = Dense(1, activation = 'sigmoid')(Y)\n",
    "\n",
    "model = Model(inputs = [IMG_FEATURES, IMG_CAPTIONS, FULL_TEXT, BIB], outputs = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3056 samples, validate on 768 samples\n",
      "Epoch 1/20\n",
      "3056/3056 [==============================] - 5s 2ms/step - loss: 0.0603 - acc: 0.9820 - val_loss: 0.1700 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16998, saving model to model-img-caption-text-bib-best.h5\n",
      "Epoch 2/20\n",
      "3056/3056 [==============================] - 2s 549us/step - loss: 0.0527 - acc: 0.9823 - val_loss: 0.4121 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16998\n",
      "Epoch 3/20\n",
      "3056/3056 [==============================] - 2s 547us/step - loss: 0.0547 - acc: 0.9849 - val_loss: 0.3307 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16998\n",
      "Epoch 4/20\n",
      "3056/3056 [==============================] - 2s 544us/step - loss: 0.0562 - acc: 0.9830 - val_loss: 0.3443 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16998\n",
      "Epoch 5/20\n",
      "3056/3056 [==============================] - 2s 554us/step - loss: 0.0594 - acc: 0.9849 - val_loss: 0.3893 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16998\n",
      "Epoch 6/20\n",
      "3056/3056 [==============================] - 2s 550us/step - loss: 0.0643 - acc: 0.9830 - val_loss: 0.4146 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16998\n",
      "Epoch 7/20\n",
      "3056/3056 [==============================] - 2s 548us/step - loss: 0.0681 - acc: 0.9830 - val_loss: 0.2254 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16998\n",
      "Epoch 8/20\n",
      "3056/3056 [==============================] - 2s 543us/step - loss: 0.0417 - acc: 0.9853 - val_loss: 0.3808 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16998\n",
      "Epoch 9/20\n",
      "3056/3056 [==============================] - 2s 546us/step - loss: 0.0590 - acc: 0.9804 - val_loss: 0.1903 - val_acc: 0.9466\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16998\n",
      "Epoch 10/20\n",
      "3056/3056 [==============================] - 2s 545us/step - loss: 0.0533 - acc: 0.9830 - val_loss: 0.3080 - val_acc: 0.9466\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16998\n",
      "Epoch 11/20\n",
      "3056/3056 [==============================] - 2s 561us/step - loss: 0.0452 - acc: 0.9856 - val_loss: 0.3055 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16998\n",
      "Epoch 12/20\n",
      "3056/3056 [==============================] - 2s 554us/step - loss: 0.0402 - acc: 0.9856 - val_loss: 0.3638 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16998\n",
      "Epoch 13/20\n",
      "3056/3056 [==============================] - 2s 547us/step - loss: 0.0393 - acc: 0.9866 - val_loss: 0.4744 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16998\n",
      "Epoch 14/20\n",
      "3056/3056 [==============================] - 2s 558us/step - loss: 0.1751 - acc: 0.9804 - val_loss: 0.4408 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16998\n",
      "Epoch 15/20\n",
      "3056/3056 [==============================] - 2s 552us/step - loss: 0.0557 - acc: 0.9856 - val_loss: 0.2792 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16998\n",
      "Epoch 16/20\n",
      "3056/3056 [==============================] - 2s 547us/step - loss: 0.0449 - acc: 0.9866 - val_loss: 0.3288 - val_acc: 0.9466\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16998\n",
      "Epoch 17/20\n",
      "3056/3056 [==============================] - 2s 553us/step - loss: 0.0505 - acc: 0.9859 - val_loss: 0.2989 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16998\n",
      "Epoch 18/20\n",
      "3056/3056 [==============================] - 2s 550us/step - loss: 0.0336 - acc: 0.9882 - val_loss: 0.2949 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16998\n",
      "Epoch 19/20\n",
      "3056/3056 [==============================] - 2s 554us/step - loss: 0.0419 - acc: 0.9872 - val_loss: 0.3969 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16998\n",
      "Epoch 20/20\n",
      "3056/3056 [==============================] - 2s 560us/step - loss: 0.0356 - acc: 0.9882 - val_loss: 0.3686 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16998\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(DATA+'model-img-caption-text-bib-best.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "results = model.fit( [fv_img,fv_img_caption,fv_full_text,fv_bib],train_labels, epochs= 20, batch_size = 64,validation_data=([fv_img_test,fv_img_test_caption,fv_full_text_test,fv_bib_test],test_labels),callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict([fv_img_test,fv_img_test_caption,fv_full_text_test,fv_bib_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predicted)):\n",
    "    if predicted[i] >= 0.5:\n",
    "        predicted[i] = 1.0\n",
    "    else :\n",
    "        predicted[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fscore 0.9424444747240769\n",
      "precision 0.9436188811188811\n",
      "recall 0.9417364813404417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.92      0.94       364\n",
      "        1.0       0.93      0.96      0.95       404\n",
      "\n",
      "avg / total       0.94      0.94      0.94       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"fscore\",f1_score(test_labels, predicted, average=\"macro\"))\n",
    "print(\"precision\",precision_score(test_labels, predicted, average=\"macro\"))\n",
    "print(\"recall\",recall_score(test_labels, predicted, average=\"macro\"))    \n",
    "\n",
    "x = classification_report(test_labels,predicted)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(DATA+'image-caption-bib-full-text-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:raghav_btp]",
   "language": "python",
   "name": "conda-env-raghav_btp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
